- Version de python

Différentes parties du code utilisent la fonction tryparallelize qui partage un job en un certain nombre d'autres, et ensuite ceux ci sont soumis à un certain nombre de qsub avec pour job un fichier dans lequel
les erreurs sont renvoyées. Ce fichier est régulièrement scanné, et le processus en cours est stoppé si la moindre ligne est apparue dans ce fichier, autrement dit si on a une erreur. Or un message d'erreur du à
la version de python peut apparaître, indiquant à l'utilisateur d'utiliser des version plus récentes de python comme 2.7.15 ou python 3. Pour régler ce souci, il faut modifier la version de python sourcée dans l
e fichier script/env.sh, car le programme est fait de façon à ce que ce fichier soit sourcé avant chaque job soumis au qsub.

- Dico

Lors de la création des tables, le programme fonctionne ainsi : il crée les tables génériques (vides), les tables spécifiques (vides), il remplit les tables génériques puis les tables spécifiques. Or pour créer
les tables spécifiques, il faut les identifiants des espèces (gene_id) et pour cela une partie des tables génériques doit être remplie. C'est pour cela que la table current_genome_db est remplie avant les autres
, après la création des tables génériques vides (il serait d'ailleurs peut être pertinent de faire créer-remplir puis créer remplir pour les génériques puis spécifiques pour avoir moins de code). Mais le vrai pr
oblème réside surtout dans le fait que l'on accède aux noms des espèces via un dictionnaire dRelationGenomeDBId_SpecieName. Sa création est testée (try-except) au début du code via l'accès à la table current_gen
ome_db mais le souci est que la table n'existe en général pas lorsque cette partie du code est parcourue. Ainsi lorsque plus tard, on veut accéder à dRelationGenomeDBId_SpecieName, celui-ci n'est pas défini. Au
lieu de relancer toujours le code, pour régler ce souci j'ai créé une fonction dico() (changer de nom) qui exporte en variable globale dRelationGenomeDBId_SpecieName ainsi que tSpeciesTable, à partir de laquelle
 dRelationGenomeDBId_SpecieName est créé et qui est parfois utilisée comme telle. Cette fonction dico() peut ainsi être placée aux endroits stratégiques du code, au niveau des étapes qui en ont besoin, afin que
ces variables existent lorsque c'est nécessaire. Le code bloque au niveau de la création des tables spécifiques ; mais le problème ne devrait pas avoir lieu plus tard dans le code, car même si on relance uniquem
ent certaines étapes, le dictionnaire devrait se créer proprement au début. Mais pour le moment j'ai mis le try-except du dictionnaire en commentaire, et on utilise la fonction dico aux endroits appropriés.
Perspectives : il serait pertinent de créer une classe avec ce dictionnaire, une classe dont on pourrait appeler les attributs dRelationGenomeDBId_SpecieName et tSpeciesTable. Cela serait plus propre, car l'expo
rt des variables globales n'est pas la meilleure solution.

- SpeciesFilter

Cette variable peut être modifiée dans le fichier config. Elle intervient dans différents endroits : au début du code au niveau du téléchargement des données, et plus tard lorsqu'on créée les tables spécifiques.
 Seules les données spécifiques des espèces indiquées seront téléchargées en utilisant le module re ; la page de téléchargement d'Ensembl FTP est scannée et seuls les fichiers correspondant à l'expression réguli
ère de speciesFilter seront téléchargés. Dans la version précédente, on pouvait appliquer ce filtre en ne téléchargeant les données que d'une espèce, ou toutes les espèces. Ici on peut indiquer plusieurs espèces
 dont le nom est séparé par une virgule. Ensuite, on fera un split(",") sur speciesFilter et on pourra itérer dessus afin de prendre en compte ces différentes espèces. Ce filtre fonctionne ainsi correctement pou
r plusieurs espèces pour le téléchargement des données, la création des tables spécifiques et également à la dernière étape, pour la récupération des données Fasta (ce filtre n'était pas appliqué à cet endroit,
mais je l'ai rajouté, sinon cela fonctionne mais on envoie des scripts inutiles qui renvoient des erreurs).

- Current_tool

lorsqu'on redémarre le programme, le remplissage de current_tool peut poser souci. J'ai donc remplacé 'insert' par 'insert ignore' afin de recommencer le remplissage en ignorant les doublons.

- Colonne "status"

Dans la nouvelle version d'Ensembl(95), la colonne "status" a visiblement été supprimée. Elle est présente dans les tables spécifiques current_gene et current_transcript (par exemple current_gene_209 et current_transcript_209 pour le gorille). Il faut supprimer cette colonne lors de la création des tables, sinon on a un décalage (pour current_transcript on a la version à la place du stable_id) qui empêche le reste du pipeline de s'exécuter correctement. Le reste des tables semble correcte, la seule chose est que certains fichiers ont davantage de colonnes que les tables qui les accueillent (method_link, genome_db,...) ; cela peut-il poser un souci ? En tout cas les tables ont l'air correctes et si elles ont n colonnes enregistrent les n premières colonnes du fichier.

- Current_tool :

J'ai rajouté un insert IGNORE pour la création de cette table créée à part. Comme ça elle ne renvoie pas de message d'erreur si elle est déjà créée et ne bloque pas la suite du processus.

- Parallélisation des composantes connexes et cliques globales :

Actuellement le programme fais les calculs non-global puis global pour les composantes connexes puis les cliques. Etant donné que les évènements sont indépendants (est-ce vraiment le cas ?) il serait peut-être judicieux de paralléliser les deux procédés pour gagner plusieurs heures.

- Calcul des composantes connexes :

Dans le script compco.pl, une variable est initialisée au début : maxnei, le nombre de lien max, qui empêche une partie de l'exécution du script si elle est dépassée. Elle était à 150, ce qui convenait pour le calcul des composantes connexes non globales ; mais ici la variable est rapidement dépassée, car d'après mes calculs certains noeuds sont liés à 1557 autres (gène 29300002158427). Du coup ça ne beug plus avec la variable mise à 1600. Mais à quoi sert une telle variable ?

- Dossier "to_save" :

Ce fichier contient les fichiers que j'ai modifiés. Je les copie régulièrement sur l'ordi local pour les sauver sur github (https://github.com/albanel/phyfoo). Je ne peux pas suivre tous les dossiers pour des raisons de place. 

- Fichiers "dangereux" :

Certains fichiers dont je ne connais pas l'utilité ont été déplacés dans un répertoire "peut_etre_utile" dans mon home sur genocluster2. Ils peuvent être dangereux car ils contiennent les mots de passe admin de la base orthocis2, qui doit rester intact.
Liste de ces fichiers :

        - tout le répertoire tmp_avoir ; ceux ci correspondent aux fichiers temporaires laissés par mon prédecesseur, je les ai gardés au cas où.
        - config/genouestDB2.conf et config/good_87.conf
        - src/temp***711.sh
        - src/dev/deletemotifdata.sh
        - scr/script/qsubrunscan1jasparMatrix.sh

- Calcul des cliques (remplissage de current_clique_element) : le programme renvoie régulièrement une erreur qui interrompt le processus car il y a trop de connexions simultanées sur la DB (protection anti intrusion). Pour éviter ce souci j'ai rajouté un time.sleep de 30 secondes entre chaque job, cela permet d'éviter ce souci tout en perdant peu de temps. Mais le souci peut persister quand même, c'est assez aléatoire, la connexion reste fragile... moyen de changer ça ? Changer la variable de max_connections_error ?

- check_database :

Pour éviter de reperdre du temps avec des tables qui ne sont pas à jour par
rapport aux fichiers téléchargés sur Ensembl (cf colonne "STATUS") je
travaille sur un petit module de vérification de la base de données. Celui ira
chercher les champs des tables d'intérêt sur la page d'Ensembl et les comparera à ceux des tables que l'on souhaite peupler.
Tous les fichiers nécessaires sont dans le dossier check_database. Ce dossier a donc été ajouté au python path du fichier run, et est également une variable du fichier de configuration "cf_checkdir" puis "checkdir". Dans le fichier BuildOrthocis on fait appelle à la fonction check_generic_tables par exemple (après la création des tables et avant leur remplissage). Celle-ci est dans le module check_database.py. Dans ce fichier, pour chaque table (ici générique) on ajoute à un dictionnaire en clé la table et en valeur la description, c'est à dire les champs de la table. Le script python execute ensuite un fichier bash (check_database.sh) pour télécharger (curl) la page d'Ensembl décrivant les données spécifiques et la mettre dans un fichier particulier (ce fichier prend en argument le répertoire check dans lequel tout se passera, sinon on aura un souci de path). Ce script bash exécutera ensuite un script python (read_html) qui traitera le fichier téléchargé par curl, et trouvera les champs des différentes tables génériques pour les mettre dans un dictionnaire. Notons que le package "beautifulSoup" pour parser le html doit fonctionner, d'où le second intérêt du fichier bash qui active un environnement dans lequel BeautifulSoup fonctionne, execute le programme puis désactive l'environnement.  
Le programma affiche les deux dictionnaires, il d'agira ensuite de les comparer pour voir si les champs sont les mêmes.

- Répertoires dans "jobs" :

Il serait peut être judicieux que le calcul des cliques se fasse dans un
dossier "CLGLOBAL" comme pour les autres jobs.

- Calcul des cliques

Etant donné le temps très long mis pour le calcul des cliques pour le global notamment, le calcul des cliques a été reprogrammé avec un outil nommé "quick cliques", codé en C++.
Script à appeler au début de Build_Orthocis.py : script/DrmaaScript_RetrieveClique2.py
Pour cela, pour chaque composante connexe :
1) Les noeuds et liens sont téléchargés dans la DB
2) Ils sont écrits dans un fichier
3) Le fichier est transformé en un format fichier spécifique nécessaire à quick cliques : un lien par ligne séparés par une virgule, chaque noeud étant un entier positif dont la valeur va de 0 à nbre de noeuds -1. Un dictionnaire dans le programme se charge de la transformation. Deux lignes en tête de fichier sont également nécessaires : le nombre de noeuds puis le nombre de liens dans le fichier (nombre en lignes). Tous les liens doivent être stockés en double.
4) Ce fichier est envoyé en input à quick_clique, dont le répertoire doit être indiqué dans le fichier conf (quick_clique_dir). Un script bash est ainsi créé et exécuté pour chaque composante connexe.
Si l'option insertion est activée :
5) Le fichier output de quick clique est récupéré, puis il est lu (les deux premières lignes, informatives, sont ignorées) et décodé pour retrouver les gene_id. Chaque clique est ajoutée à une liste de cliques. Pour chaque clique de cette liste, on va créer la ligne à insérer dans la DB, avec le gène pour la colonne de l'espèce si elle est représentée, et "NULL" sinon. La ligne est écrite dans un fichier à insérer. Dans la version précédente pour chaque clique les lignes étaient insérées les unes après les autres, mais l'utilisation du load data local infile permet d'accélérer très fortement le calcul des cliques : on passe de 2 semaines de calcul à quelques heures seulement. L'utilisation de quick cliques permet sans doute d'accélérer, mais dans une moindre mesure. A tester cette config avec networkx ?
6) Le fichier du job_id est inséré dans la DB. Notons que le job_id est inséré également pour pouvoir supprimer facilement ces lignes en cas d'erreur.
Attention si on télécharge quick_clique directement depuis git : certaines
modifications doivent être apportés au code C++ car certaines infos sont
dirigés vers la sortie erreur par le programme, et ainsi vont dans le fichier
erreur qui est scanné et qui provoque l'arrêt du job s'il contient quoique ce
soit. 
Modifications à apporter après avoir téléchargé quick_clique : 
a) Dans le fichier makefile, l'option "printOneByOne" doit être activée sinon
les cliques ne s'impriment pas.
b) Tools.cpp (dans src) : certaines lignes permettent d'imprimer (dans la
sortie erreur) le nombre de cliques et le nom de l'algo utilisé. Ligne à
commenter : //fprintf(stderr, "%s: ", pAlgorithm->GetName().c_str()); et
//fflush(stderr); pour le nom de l'algo

//fprintf(stderr, "%ld maximal cliques, ", cliqueCount);
//fprintf(stderr, "in %f seconds\n",
//(double)(end-start)/(double)(CLOCKS_PER_SEC));
pour le nombre de cliques.

L'utilisation de quick_cliques est découplée du reste pour le debug, mais il est important que les étape de traitement de fichier et d'insertion dans la DB se fassent dans le même job, ainsi les tables finies s'insèrent dans la DB le temps que les autres s'insèrent, ce qui permet de gagner du temps et d'éviter de saturer la DB.

Modification de la fonction fillCliquesTable + création de la fonction computeCliques :
Les deux fonctions sont les mêmes sauf que dans le fichier arg, un booléen est noté en plus, False pour fillCliquesTable et True pour computeCliques. Ce booléen indique au fichier RetrieveClique.py s'il doit calculer les cliques ou les insérer dans la DB.

La variable idxcount était globale avant pour pouvoir incrémenter tous les jobs. Mais cela empêchait le fait de pouvoir aller dans le bon directory correspondant puisque la variable s'incrémentait. Par exemple, le calcul des cliques pour le job 1 se faisait dans le dir 1. Mais l'insertion se faisait à partir du dir 2, vide puisque le fichier se trouvait dans le dir 1.

Une fois que la table est créée, on ajoute une colonne auto_increment clique_id, comme pour la version précédente mais cette fois-ci à la fin.

Deux fichiers monitorent le bon fonctionnement du programme RetrieveClique : "ok_for_compute" et "ok_for_insertion". Lorsqu'une partie du programme est finie, le fichier correspondant est créée, et non s'il y a une erreur. Et les parties correspondantes ne se font uniquement si le fichier correspondant n'est pas présent dans le répertoire. Ainsi, les jobs déjà exécutés auront ces fichiers dans le répertoire ne se referont pas inutilement si l'utilisateur relance tout s'il y a une erreur.

- Transformation du script json_faster en global :






