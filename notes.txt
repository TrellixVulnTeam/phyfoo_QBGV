- Version de python

Différentes parties du code utilisent la fonction tryparallelize qui partage un job en un certain nombre d'autres, et ensuite ceux ci sont soumis à un certain nombre de qsub avec pour job un fichier dans lequel
les erreurs sont renvoyées. Ce fichier est régulièrement scanné, et le processus en cours est stoppé si la moindre ligne est apparue dans ce fichier, autrement dit si on a une erreur. Or un message d'erreur du à
la version de python peut apparaître, indiquant à l'utilisateur d'utiliser des version plus récentes de python comme 2.7.15 ou python 3. Pour régler ce souci, il faut modifier la version de python sourcée dans l
e fichier script/env.sh, car le programme est fait de façon à ce que ce fichier soit sourcé avant chaque job soumis au qsub.

- Dico

Lors de la création des tables, le programme fonctionne ainsi : il crée les tables génériques (vides), les tables spécifiques (vides), il remplit les tables génériques puis les tables spécifiques. Or pour créer
les tables spécifiques, il faut les identifiants des espèces (gene_id) et pour cela une partie des tables génériques doit être remplie. C'est pour cela que la table current_genome_db est remplie avant les autres
, après la création des tables génériques vides (il serait d'ailleurs peut être pertinent de faire créer-remplir puis créer remplir pour les génériques puis spécifiques pour avoir moins de code). Mais le vrai pr
oblème réside surtout dans le fait que l'on accède aux noms des espèces via un dictionnaire dRelationGenomeDBId_SpecieName. Sa création est testée (try-except) au début du code via l'accès à la table current_gen
ome_db mais le souci est que la table n'existe en général pas lorsque cette partie du code est parcourue. Ainsi lorsque plus tard, on veut accéder à dRelationGenomeDBId_SpecieName, celui-ci n'est pas défini. Au
lieu de relancer toujours le code, pour régler ce souci j'ai créé une fonction dico() (changer de nom) qui exporte en variable globale dRelationGenomeDBId_SpecieName ainsi que tSpeciesTable, à partir de laquelle
 dRelationGenomeDBId_SpecieName est créé et qui est parfois utilisée comme telle. Cette fonction dico() peut ainsi être placée aux endroits stratégiques du code, au niveau des étapes qui en ont besoin, afin que
ces variables existent lorsque c'est nécessaire. Le code bloque au niveau de la création des tables spécifiques ; mais le problème ne devrait pas avoir lieu plus tard dans le code, car même si on relance uniquem
ent certaines étapes, le dictionnaire devrait se créer proprement au début. Mais pour le moment j'ai mis le try-except du dictionnaire en commentaire, et on utilise la fonction dico aux endroits appropriés.
Perspectives : il serait pertinent de créer une classe avec ce dictionnaire, une classe dont on pourrait appeler les attributs dRelationGenomeDBId_SpecieName et tSpeciesTable. Cela serait plus propre, car l'expo
rt des variables globales n'est pas la meilleure solution.

- SpeciesFilter

Cette variable peut être modifiée dans le fichier config. Elle intervient dans différents endroits : au début du code au niveau du téléchargement des données, et plus tard lorsqu'on créée les tables spécifiques.
 Seules les données spécifiques des espèces indiquées seront téléchargées en utilisant le module re ; la page de téléchargement d'Ensembl FTP est scannée et seuls les fichiers correspondant à l'expression réguli
ère de speciesFilter seront téléchargés. Dans la version précédente, on pouvait appliquer ce filtre en ne téléchargeant les données que d'une espèce, ou toutes les espèces. Ici on peut indiquer plusieurs espèces
 dont le nom est séparé par une virgule. Ensuite, on fera un split(",") sur speciesFilter et on pourra itérer dessus afin de prendre en compte ces différentes espèces. Ce filtre fonctionne ainsi correctement pou
r plusieurs espèces pour le téléchargement des données, la création des tables spécifiques et également à la dernière étape, pour la récupération des données Fasta (ce filtre n'était pas appliqué à cet endroit,
mais je l'ai rajouté, sinon cela fonctionne mais on envoie des scripts inutiles qui renvoient des erreurs).

- Current_tool

lorsqu'on redémarre le programme, le remplissage de current_tool peut poser souci. J'ai donc remplacé 'insert' par 'insert ignore' afin de recommencer le remplissage en ignorant les doublons.

- Colonne "status"

Dans la nouvelle version d'Ensembl(95), la colonne "status" a visiblement été supprimée. Elle est présente dans les tables spécifiques current_gene et current_transcript (par exemple current_gene_209 et current_transcript_209 pour le gorille). Il faut supprimer cette colonne lors de la création des tables, sinon on a un décalage (pour current_transcript on a la version à la place du stable_id) qui empêche le reste du pipeline de s'exécuter correctement. Le reste des tables semble correcte, la seule chose est que certains fichiers ont davantage de colonnes que les tables qui les accueillent (method_link, genome_db,...) ; cela peut-il poser un souci ? En tout cas les tables ont l'air correctes et si elles ont n colonnes enregistrent les n premières colonnes du fichier.

- Current_tool :

J'ai rajouté un insert IGNORE pour la création de cette table créée à part. Comme ça elle ne renvoie pas de message d'erreur si elle est déjà créée et ne bloque pas la suite du processus.

- Parallélisation des composantes connexes et cliques globales :

Actuellement le programme fais les calculs non-global puis global pour les composantes connexes puis les cliques. Etant donné que les évènements sont indépendants (est-ce vraiment le cas ?) il serait peut-être judicieux de paralléliser les deux procédés pour gagner plusieurs heures.

- Calcul des composantes connexes :

Dans le script compco.pl, une variable est initialisée au début : maxnei, le nombre de lien max, qui empêche une partie de l'exécution du script si elle est dépassée. Elle était à 150, ce qui convenait pour le calcul des composantes connexes non globales ; mais ici la variable est rapidement dépassée, car d'après mes calculs certains noeuds sont liés à 1557 autres (gène 29300002158427). Du coup ça ne beug plus avec la variable mise à 1600. Mais à quoi sert une telle variable ?

- Dossier "to_save" :

Ce fichier contient les fichiers que j'ai modifiés. Je les copie régulièrement sur l'ordi local pour les sauver sur github (https://github.com/albanel/phyfoo). Je ne peux pas suivre tous les dossiers pour des raisons de place. 

- Fichiers "dangereux" :

Certains fichiers dont je ne connais pas l'utilité ont été déplacés dans un répertoire "peut_etre_utile" dans mon home sur genocluster2. Ils peuvent être dangereux car ils contiennent les mots de passe admin de la base orthocis2, qui doit rester intact.
Liste de ces fichiers :

        - tout le répertoire tmp_avoir ; ceux ci correspondent aux fichiers temporaires laissés par mon prédecesseur, je les ai gardés au cas où.
        - config/genouestDB2.conf et config/good_87.conf
        - src/temp***711.sh
        - src/dev/deletemotifdata.sh
        - scr/script/qsubrunscan1jasparMatrix.sh

- Calcul des cliques (remplissage de current_clique_element) : le programme renvoie régulièrement une erreur qui interrompt le processus car il y a trop de connexions simultanées sur la DB (protection anti intrusion). Pour éviter ce souci j'ai rajouté un time.sleep de 30 secondes entre chaque job, cela permet d'éviter ce souci tout en perdant peu de temps. Mais le souci peut persister quand même, c'est assez aléatoire, la connexion reste fragile... moyen de changer ça ? Changer la variable de max_connections_error ?

- check_database :

Pour éviter de reperdre du temps avec des tables qui ne sont pas à jour par
rapport aux fichiers téléchargés sur Ensembl (cf colonne "STATUS") je
travaille sur un petit module de vérification de la base de données. Celui ira
chercher les champs des tables d'intérêt sur la page d'Ensembl et les comparera à ceux des tables que l'on souhaite peupler.
Tous les fichiers nécessaires sont dans le dossier check_database. Ce dossier a donc été ajouté au python path du fichier run, et est également une variable du fichier de configuration "cf_checkdir" puis "checkdir". Dans le fichier BuildOrthocis on fait appelle à la fonction check_generic_tables par exemple (après la création des tables et avant leur remplissage). Celle-ci est dans le module check_database.py. Dans ce fichier, pour chaque table (ici générique) on ajoute à un dictionnaire en clé la table et en valeur la description, c'est à dire les champs de la table. Le script python execute ensuite un fichier bash (check_database.sh) pour télécharger (curl) la page d'Ensembl décrivant les données spécifiques et la mettre dans un fichier particulier (ce fichier prend en argument le répertoire check dans lequel tout se passera, sinon on aura un souci de path). Ce script bash exécutera ensuite un script python (read_html) qui traitera le fichier téléchargé par curl, et trouvera les champs des différentes tables génériques pour les mettre dans un dictionnaire. Notons que le package "beautifulSoup" pour parser le html doit fonctionner, d'où le second intérêt du fichier bash qui active un environnement dans lequel BeautifulSoup fonctionne, execute le programme puis désactive l'environnement.  
Le programma affiche les deux dictionnaires, il d'agira ensuite de les comparer pour voir si les champs sont les mêmes.

- Répertoires dans "jobs" :

Il serait peut être judicieux que le calcul des cliques se fasse dans un
dossier "CLGLOBAL" comme pour les autres jobs.



































